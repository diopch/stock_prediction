{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "cheikh_stacking_arima_only.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d68dc098"
      },
      "source": [
        "# Importation"
      ],
      "id": "d68dc098"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "862d70b8"
      },
      "source": [
        "from sklearn.metrics import make_scorer,SCORERS,mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression,SGDRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "id": "862d70b8",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9fd8f69"
      },
      "source": [
        "# Load dataframe"
      ],
      "id": "c9fd8f69"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "fc4df374",
        "outputId": "fab36d5f-0088-4919-92e2-bb261efa278a"
      },
      "source": [
        "data = pd.read_csv(\"predictions_vinci\")\n",
        "data.head()"
      ],
      "id": "fc4df374",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>prediction</th>\n",
              "      <th>conf_low</th>\n",
              "      <th>conf_high</th>\n",
              "      <th>true</th>\n",
              "      <th>conf_std</th>\n",
              "      <th>Date</th>\n",
              "      <th>perf_pred</th>\n",
              "      <th>perf_true</th>\n",
              "      <th>perf_low</th>\n",
              "      <th>perf_high</th>\n",
              "      <th>garch_pred</th>\n",
              "      <th>vol_variation</th>\n",
              "      <th>prediction_cnn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>101.311661</td>\n",
              "      <td>100.229275</td>\n",
              "      <td>98.853678</td>\n",
              "      <td>101.604872</td>\n",
              "      <td>100.998656</td>\n",
              "      <td>0.701848</td>\n",
              "      <td>2016-09-29</td>\n",
              "      <td>-0.010684</td>\n",
              "      <td>-0.003090</td>\n",
              "      <td>-0.024262</td>\n",
              "      <td>0.002894</td>\n",
              "      <td>21.300782</td>\n",
              "      <td>-0.004677</td>\n",
              "      <td>0.000385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>100.998656</td>\n",
              "      <td>102.686427</td>\n",
              "      <td>101.292483</td>\n",
              "      <td>104.080370</td>\n",
              "      <td>101.535259</td>\n",
              "      <td>0.711209</td>\n",
              "      <td>2016-09-30</td>\n",
              "      <td>0.016711</td>\n",
              "      <td>0.005313</td>\n",
              "      <td>0.002909</td>\n",
              "      <td>0.030512</td>\n",
              "      <td>21.186977</td>\n",
              "      <td>-0.005343</td>\n",
              "      <td>0.000222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>101.535259</td>\n",
              "      <td>101.803834</td>\n",
              "      <td>100.377070</td>\n",
              "      <td>103.230599</td>\n",
              "      <td>101.445808</td>\n",
              "      <td>0.727954</td>\n",
              "      <td>2016-10-03</td>\n",
              "      <td>0.002645</td>\n",
              "      <td>-0.000881</td>\n",
              "      <td>-0.011407</td>\n",
              "      <td>0.016697</td>\n",
              "      <td>21.075146</td>\n",
              "      <td>-0.005278</td>\n",
              "      <td>0.000415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>101.445808</td>\n",
              "      <td>101.608547</td>\n",
              "      <td>100.183373</td>\n",
              "      <td>103.033721</td>\n",
              "      <td>101.997306</td>\n",
              "      <td>0.727143</td>\n",
              "      <td>2016-10-04</td>\n",
              "      <td>0.001604</td>\n",
              "      <td>0.005436</td>\n",
              "      <td>-0.012444</td>\n",
              "      <td>0.015653</td>\n",
              "      <td>21.142841</td>\n",
              "      <td>0.003212</td>\n",
              "      <td>0.000095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>101.997306</td>\n",
              "      <td>101.715455</td>\n",
              "      <td>100.285934</td>\n",
              "      <td>103.144976</td>\n",
              "      <td>100.298096</td>\n",
              "      <td>0.729361</td>\n",
              "      <td>2016-10-05</td>\n",
              "      <td>-0.002763</td>\n",
              "      <td>-0.016659</td>\n",
              "      <td>-0.016779</td>\n",
              "      <td>0.011252</td>\n",
              "      <td>21.256323</td>\n",
              "      <td>0.005367</td>\n",
              "      <td>0.000280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   yesterday  ...  vol_variation  prediction_cnn\n",
              "0           0  101.311661  ...      -0.004677        0.000385\n",
              "1           1  100.998656  ...      -0.005343        0.000222\n",
              "2           2  101.535259  ...      -0.005278        0.000415\n",
              "3           3  101.445808  ...       0.003212        0.000095\n",
              "4           4  101.997306  ...       0.005367        0.000280\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74334a82",
        "outputId": "a4d665c5-cc4b-48e3-f64b-2df69983f831"
      },
      "source": [
        "data.shape"
      ],
      "id": "74334a82",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1131, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "aFExHZl_UaGk",
        "outputId": "8fa11004-3488-4929-88e7-ac9aea0f8abf"
      },
      "source": [
        "data.loc[:800].tail()"
      ],
      "id": "aFExHZl_UaGk",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>prediction</th>\n",
              "      <th>conf_low</th>\n",
              "      <th>conf_high</th>\n",
              "      <th>true</th>\n",
              "      <th>conf_std</th>\n",
              "      <th>Date</th>\n",
              "      <th>perf_pred</th>\n",
              "      <th>perf_true</th>\n",
              "      <th>perf_low</th>\n",
              "      <th>perf_high</th>\n",
              "      <th>garch_pred</th>\n",
              "      <th>vol_variation</th>\n",
              "      <th>prediction_cnn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>852</td>\n",
              "      <td>167.608549</td>\n",
              "      <td>167.621782</td>\n",
              "      <td>165.804690</td>\n",
              "      <td>169.438874</td>\n",
              "      <td>166.130379</td>\n",
              "      <td>0.927105</td>\n",
              "      <td>2020-01-30</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>-0.008819</td>\n",
              "      <td>-0.010762</td>\n",
              "      <td>0.010920</td>\n",
              "      <td>91.552026</td>\n",
              "      <td>-0.095035</td>\n",
              "      <td>0.000095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>853</td>\n",
              "      <td>166.130379</td>\n",
              "      <td>164.764191</td>\n",
              "      <td>162.903386</td>\n",
              "      <td>166.624997</td>\n",
              "      <td>164.570069</td>\n",
              "      <td>0.949408</td>\n",
              "      <td>2020-01-31</td>\n",
              "      <td>-0.008224</td>\n",
              "      <td>-0.009392</td>\n",
              "      <td>-0.019424</td>\n",
              "      <td>0.002977</td>\n",
              "      <td>82.850691</td>\n",
              "      <td>-0.095043</td>\n",
              "      <td>0.000095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>854</td>\n",
              "      <td>164.570069</td>\n",
              "      <td>164.364885</td>\n",
              "      <td>162.523678</td>\n",
              "      <td>166.206092</td>\n",
              "      <td>165.062804</td>\n",
              "      <td>0.939409</td>\n",
              "      <td>2020-02-03</td>\n",
              "      <td>-0.001247</td>\n",
              "      <td>0.002994</td>\n",
              "      <td>-0.012435</td>\n",
              "      <td>0.009941</td>\n",
              "      <td>70.466986</td>\n",
              "      <td>-0.149470</td>\n",
              "      <td>0.000095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>855</td>\n",
              "      <td>165.062804</td>\n",
              "      <td>166.784476</td>\n",
              "      <td>164.931914</td>\n",
              "      <td>168.637039</td>\n",
              "      <td>167.854903</td>\n",
              "      <td>0.945202</td>\n",
              "      <td>2020-02-04</td>\n",
              "      <td>0.010430</td>\n",
              "      <td>0.016915</td>\n",
              "      <td>-0.000793</td>\n",
              "      <td>0.021654</td>\n",
              "      <td>91.823870</td>\n",
              "      <td>0.303076</td>\n",
              "      <td>0.000095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>856</td>\n",
              "      <td>167.854903</td>\n",
              "      <td>167.943377</td>\n",
              "      <td>166.073853</td>\n",
              "      <td>169.812901</td>\n",
              "      <td>170.893370</td>\n",
              "      <td>0.953856</td>\n",
              "      <td>2020-02-05</td>\n",
              "      <td>0.000527</td>\n",
              "      <td>0.018102</td>\n",
              "      <td>-0.010611</td>\n",
              "      <td>0.011665</td>\n",
              "      <td>80.583939</td>\n",
              "      <td>-0.122408</td>\n",
              "      <td>0.000095</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0   yesterday  ...  vol_variation  prediction_cnn\n",
              "796         852  167.608549  ...      -0.095035        0.000095\n",
              "797         853  166.130379  ...      -0.095043        0.000095\n",
              "798         854  164.570069  ...      -0.149470        0.000095\n",
              "799         855  165.062804  ...       0.303076        0.000095\n",
              "800         856  167.854903  ...      -0.122408        0.000095\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17a96da4"
      },
      "source": [
        "feature_to_remove = [\"Unnamed: 0\",\"yesterday\",\"prediction\",\"conf_low\",\"conf_high\",\"true\",\"Date\", \"garch_pred\", \"vol_variation\",\t\"prediction_cnn\"]"
      ],
      "id": "17a96da4",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f9c4a7b"
      },
      "source": [
        "data = data.drop(columns=feature_to_remove).loc[:800]"
      ],
      "id": "8f9c4a7b",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "f1d76978",
        "outputId": "09407071-dae6-4866-9efd-c032fd4f1de0"
      },
      "source": [
        "data.head()"
      ],
      "id": "f1d76978",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conf_std</th>\n",
              "      <th>perf_pred</th>\n",
              "      <th>perf_true</th>\n",
              "      <th>perf_low</th>\n",
              "      <th>perf_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.701848</td>\n",
              "      <td>-0.010684</td>\n",
              "      <td>-0.003090</td>\n",
              "      <td>-0.024262</td>\n",
              "      <td>0.002894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.711209</td>\n",
              "      <td>0.016711</td>\n",
              "      <td>0.005313</td>\n",
              "      <td>0.002909</td>\n",
              "      <td>0.030512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.727954</td>\n",
              "      <td>0.002645</td>\n",
              "      <td>-0.000881</td>\n",
              "      <td>-0.011407</td>\n",
              "      <td>0.016697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.727143</td>\n",
              "      <td>0.001604</td>\n",
              "      <td>0.005436</td>\n",
              "      <td>-0.012444</td>\n",
              "      <td>0.015653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.729361</td>\n",
              "      <td>-0.002763</td>\n",
              "      <td>-0.016659</td>\n",
              "      <td>-0.016779</td>\n",
              "      <td>0.011252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   conf_std  perf_pred  perf_true  perf_low  perf_high\n",
              "0  0.701848  -0.010684  -0.003090 -0.024262   0.002894\n",
              "1  0.711209   0.016711   0.005313  0.002909   0.030512\n",
              "2  0.727954   0.002645  -0.000881 -0.011407   0.016697\n",
              "3  0.727143   0.001604   0.005436 -0.012444   0.015653\n",
              "4  0.729361  -0.002763  -0.016659 -0.016779   0.011252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "544bd1c9"
      },
      "source": [
        "X = data.copy().drop(columns=\"perf_true\")\n",
        "y= data[\"perf_true\"]"
      ],
      "id": "544bd1c9",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9374d7d",
        "outputId": "3895725a-e265-449b-d53e-10cf2da6f326"
      },
      "source": [
        "mae_arima = mean_absolute_error(data.perf_true,data.perf_pred)\n",
        "mae_arima"
      ],
      "id": "a9374d7d",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00521128782478184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0780ae2"
      },
      "source": [
        "# GridSearch SVM"
      ],
      "id": "b0780ae2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cd35fb1",
        "outputId": "861b8a0a-8221-4323-e9c3-2f64a3e5a5d9"
      },
      "source": [
        "SCORERS.keys()"
      ],
      "id": "8cd35fb1",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88bcc9da",
        "outputId": "431da3c2-6915-4e74-da2b-86511feaf75a"
      },
      "source": [
        "\n",
        "# Instanciate model\n",
        "model_svm = Pipeline([(\"scale\",StandardScaler()),(\"svm\",SVR())])\n",
        "\n",
        "# Hyperparameter search space\n",
        "search_space = {\n",
        "    'svm__kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
        "    'svm__C': stats.uniform(0.01, 1000),\n",
        "    'svm__gamma': stats.loguniform(0.001,10),\n",
        "    'svm__coef0': stats.uniform(-5,5),\n",
        "}\n",
        "\n",
        "# Instanciate Random Search\n",
        "search_svm = RandomizedSearchCV(\n",
        "    model_svm, search_space,\n",
        "    n_jobs=-1, scoring='neg_mean_absolute_error', cv=5, n_iter=1, verbose=0)\n",
        "\n",
        "\n",
        "search_svm.fit(X,y)"
      ],
      "id": "88bcc9da",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=Pipeline(memory=None,\n",
              "                                      steps=[('scale',\n",
              "                                              StandardScaler(copy=True,\n",
              "                                                             with_mean=True,\n",
              "                                                             with_std=True)),\n",
              "                                             ('svm',\n",
              "                                              SVR(C=1.0, cache_size=200,\n",
              "                                                  coef0=0.0, degree=3,\n",
              "                                                  epsilon=0.1, gamma='scale',\n",
              "                                                  kernel='rbf', max_iter=-1,\n",
              "                                                  shrinking=True, tol=0.001,\n",
              "                                                  verbose=False))],\n",
              "                                      verbose=False),\n",
              "                   iid='deprecated', n_iter=1, n_jobs=-1,\n",
              "                   param_distri...t 0x7fdf67f73110>,\n",
              "                                        'svm__coef0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fdf1617cad0>,\n",
              "                                        'svm__gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fdf1617c950>,\n",
              "                                        'svm__kernel': ['linear', 'poly', 'rbf',\n",
              "                                                        'sigmoid']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='neg_mean_absolute_error',\n",
              "                   verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68d6f337",
        "outputId": "4fcc28cc-b691-4e3f-b858-438799443dc6"
      },
      "source": [
        "search_svm.best_estimator_"
      ],
      "id": "68d6f337",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svm',\n",
              "                 SVR(C=865.2182590287774, cache_size=200,\n",
              "                     coef0=-4.514718799937068, degree=3, epsilon=0.1,\n",
              "                     gamma=0.01540299603779898, kernel='linear', max_iter=-1,\n",
              "                     shrinking=True, tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cc68fe9",
        "outputId": "112b82eb-e893-4a1c-e81f-fcbb60c7fbc7"
      },
      "source": [
        "search_svm.best_score_ "
      ],
      "id": "2cc68fe9",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.011892484654970713"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60ccfa53"
      },
      "source": [
        "# GridSearch KNN"
      ],
      "id": "60ccfa53"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c58f54c8",
        "outputId": "5cb082ed-ed49-4e31-ec4f-c8847650a3a4"
      },
      "source": [
        "model_knn = Pipeline([(\"scale\",StandardScaler()),(\"knn\",KNeighborsRegressor())])\n",
        "\n",
        "param_grid_knn =  {'knn__n_neighbors': range(2,50)}\n",
        "search_knn = GridSearchCV(model_knn, param_grid=param_grid_knn, \n",
        "                          cv=5, n_jobs=-1, verbose=0, scoring='neg_mean_absolute_error')\n",
        "search_knn.fit(X,y)"
      ],
      "id": "c58f54c8",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('knn',\n",
              "                                        KNeighborsRegressor(algorithm='auto',\n",
              "                                                            leaf_size=30,\n",
              "                                                            metric='minkowski',\n",
              "                                                            metric_params=None,\n",
              "                                                            n_jobs=None,\n",
              "                                                            n_neighbors=5, p=2,\n",
              "                                                            weights='uniform'))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'knn__n_neighbors': range(2, 50)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14919d61",
        "outputId": "79b7ab67-045c-4cc7-f449-2b7801a1093b"
      },
      "source": [
        "search_knn.best_estimator_"
      ],
      "id": "14919d61",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('knn',\n",
              "                 KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
              "                                     metric='minkowski', metric_params=None,\n",
              "                                     n_jobs=None, n_neighbors=46, p=2,\n",
              "                                     weights='uniform'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88cd2a00",
        "outputId": "48b32d6e-31fd-421a-c597-4e4b8ff49cc7"
      },
      "source": [
        "search_knn.best_score_"
      ],
      "id": "88cd2a00",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.005511916807667523"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75f5d3b1"
      },
      "source": [
        "# GridSearch Ridge"
      ],
      "id": "75f5d3b1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6045f306",
        "outputId": "077e5ee2-e657-48b1-cc8e-0f9017b22bcc"
      },
      "source": [
        "model_ridge = Pipeline([(\"scale\",StandardScaler()),(\"ridge\",Ridge())])\n",
        "param_grid_ridge =  {'ridge__alpha': np.linspace(0.0001,2,num=1000)}\n",
        "search_ridge = GridSearchCV(model_ridge, param_grid=param_grid_ridge, \n",
        "                              cv=5, n_jobs=-1, verbose=0, scoring='neg_mean_absolute_error')\n",
        "search_ridge.fit(X,y)"
      ],
      "id": "6045f306",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('ridge',\n",
              "                                        Ridge(alpha=1.0, copy_X=True,\n",
              "                                              fit_intercept=True, max_iter=None,\n",
              "                                              normalize=False,\n",
              "                                              random_state=None, solver='auto',\n",
              "                                              tol=0.001))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'ridge__alpha': array([1.0000...\n",
              "       1.96196386e+00, 1.96396577e+00, 1.96596767e+00, 1.96796957e+00,\n",
              "       1.96997147e+00, 1.97197337e+00, 1.97397528e+00, 1.97597718e+00,\n",
              "       1.97797908e+00, 1.97998098e+00, 1.98198288e+00, 1.98398478e+00,\n",
              "       1.98598669e+00, 1.98798859e+00, 1.98999049e+00, 1.99199239e+00,\n",
              "       1.99399429e+00, 1.99599620e+00, 1.99799810e+00, 2.00000000e+00])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9569a02a",
        "outputId": "6d6d84bb-21f9-461a-96f8-df7360820760"
      },
      "source": [
        "search_ridge.best_estimator_"
      ],
      "id": "9569a02a",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('ridge',\n",
              "                 Ridge(alpha=2.0, copy_X=True, fit_intercept=True,\n",
              "                       max_iter=None, normalize=False, random_state=None,\n",
              "                       solver='auto', tol=0.001))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20b9c75",
        "outputId": "51442eee-5fb6-42c2-95dd-ea4532c4bce3"
      },
      "source": [
        "search_ridge.best_score_"
      ],
      "id": "e20b9c75",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0052512351415269515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c9840b6"
      },
      "source": [
        "# GridSearch Lasso"
      ],
      "id": "8c9840b6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "078e5361",
        "outputId": "b89879cd-2849-473c-e8c9-9ffcbf21bd1d"
      },
      "source": [
        "model_lasso = Pipeline([(\"scale\",StandardScaler()),(\"lasso\",Lasso())])\n",
        "param_grid_lasso =  {'lasso__alpha': np.linspace(0.0001,2,num=1000)}\n",
        "search_lasso = GridSearchCV(model_lasso, param_grid=param_grid_lasso, \n",
        "                              cv=5, n_jobs=-1, verbose=0, scoring='neg_mean_absolute_error')\n",
        "search_lasso.fit(X,y)"
      ],
      "id": "078e5361",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('lasso',\n",
              "                                        Lasso(alpha=1.0, copy_X=True,\n",
              "                                              fit_intercept=True, max_iter=1000,\n",
              "                                              normalize=False, positive=False,\n",
              "                                              precompute=False,\n",
              "                                              random_state=None,\n",
              "                                              selection='cyclic', tol=0.0001,\n",
              "                                              warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='depreca...\n",
              "       1.96196386e+00, 1.96396577e+00, 1.96596767e+00, 1.96796957e+00,\n",
              "       1.96997147e+00, 1.97197337e+00, 1.97397528e+00, 1.97597718e+00,\n",
              "       1.97797908e+00, 1.97998098e+00, 1.98198288e+00, 1.98398478e+00,\n",
              "       1.98598669e+00, 1.98798859e+00, 1.98999049e+00, 1.99199239e+00,\n",
              "       1.99399429e+00, 1.99599620e+00, 1.99799810e+00, 2.00000000e+00])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94db4b74",
        "outputId": "29f489ac-b702-44bd-e4fa-ba2a8ae3f52f"
      },
      "source": [
        "search_lasso.best_estimator_"
      ],
      "id": "94db4b74",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('lasso',\n",
              "                 Lasso(alpha=0.0001, copy_X=True, fit_intercept=True,\n",
              "                       max_iter=1000, normalize=False, positive=False,\n",
              "                       precompute=False, random_state=None, selection='cyclic',\n",
              "                       tol=0.0001, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e03e90ac",
        "outputId": "298ec226-3f85-4eda-c760-63d8dcefc235"
      },
      "source": [
        "search_lasso.best_score_"
      ],
      "id": "e03e90ac",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.005225798051195897"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "870fb6c2"
      },
      "source": [
        "# GridSearch  SGD"
      ],
      "id": "870fb6c2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "310a769f",
        "outputId": "31270799-ced4-4485-e844-29773588e1ba"
      },
      "source": [
        "model_sgd = Pipeline([(\"scale\",StandardScaler()),(\"sgd\",SGDRegressor())]) \n",
        "param_grid_sgd =  {'sgd__alpha': np.linspace(0.0001,2,num=100),\n",
        "                  'sgd__penalty': [\"l2\", \"l1\", \"elasticnet\"],\n",
        "                  \"sgd__l1_ratio\" :np.linspace(0,1,num=10) }\n",
        "search_sgd = GridSearchCV(model_sgd, param_grid=param_grid_sgd, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_sgd.fit(X,y)"
      ],
      "id": "310a769f",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3000 candidates, totalling 15000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    3.4s\n",
            "[Parallel(n_jobs=-1)]: Done 4540 tasks      | elapsed:   21.9s\n",
            "[Parallel(n_jobs=-1)]: Done 11036 tasks      | elapsed:   51.9s\n",
            "[Parallel(n_jobs=-1)]: Done 15000 out of 15000 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('sgd',\n",
              "                                        SGDRegressor(alpha=0.0001,\n",
              "                                                     average=False,\n",
              "                                                     early_stopping=False,\n",
              "                                                     epsilon=0.1, eta0=0.01,\n",
              "                                                     fit_intercept=True,\n",
              "                                                     l1_ratio=0.15,\n",
              "                                                     learning_rate='invscaling',\n",
              "                                                     loss='squared_loss',\n",
              "                                                     max_iter=1000,\n",
              "                                                     n_iter_no_change=5,\n",
              "                                                     penalty='l...\n",
              "       1.85859293e+00, 1.87879394e+00, 1.89899495e+00, 1.91919596e+00,\n",
              "       1.93939697e+00, 1.95959798e+00, 1.97979899e+00, 2.00000000e+00]),\n",
              "                         'sgd__l1_ratio': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
              "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n",
              "                         'sgd__penalty': ['l2', 'l1', 'elasticnet']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5852e28e",
        "outputId": "752df7fd-6746-4237-c7c8-4ed4c4857763"
      },
      "source": [
        "search_sgd.best_estimator_"
      ],
      "id": "5852e28e",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('sgd',\n",
              "                 SGDRegressor(alpha=0.0001, average=False, early_stopping=False,\n",
              "                              epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
              "                              l1_ratio=0.1111111111111111,\n",
              "                              learning_rate='invscaling', loss='squared_loss',\n",
              "                              max_iter=1000, n_iter_no_change=5, penalty='l1',\n",
              "                              power_t=0.25, random_state=None, shuffle=True,\n",
              "                              tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                              warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "051eecf6",
        "outputId": "cfcfd7e7-db17-4197-92d5-e0e9df95e22a"
      },
      "source": [
        "search_sgd.best_score_"
      ],
      "id": "051eecf6",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0052024894567049345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7d7845c"
      },
      "source": [
        "# GridSearch Descision Tree"
      ],
      "id": "b7d7845c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77b8d0ad",
        "outputId": "e3d7806a-9b7c-4791-eda0-bd7dc610cd23"
      },
      "source": [
        "model_des_tree = Pipeline([(\"scale\",StandardScaler()),(\"desTree\",DecisionTreeRegressor())]) \n",
        "param_grid_des_tree =  {'desTree__max_depth': range(2,100),\n",
        "                  \"desTree__min_samples_leaf\" :range(2,100) }\n",
        "search_des_tree = GridSearchCV(model_des_tree, param_grid=param_grid_des_tree, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_des_tree.fit(X,y)"
      ],
      "id": "77b8d0ad",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9604 candidates, totalling 48020 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done 2332 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done 5580 tasks      | elapsed:   26.4s\n",
            "[Parallel(n_jobs=-1)]: Done 10108 tasks      | elapsed:   47.7s\n",
            "[Parallel(n_jobs=-1)]: Done 15948 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 23068 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 31500 tasks      | elapsed:  2.5min\n",
            "[Parallel(n_jobs=-1)]: Done 41212 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done 48020 out of 48020 | elapsed:  3.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('desTree',\n",
              "                                        DecisionTreeRegressor(ccp_alpha=0.0,\n",
              "                                                              criterion='mse',\n",
              "                                                              max_depth=None,\n",
              "                                                              max_features=None,\n",
              "                                                              max_leaf_nodes=None,\n",
              "                                                              min_impurity_decrease=0.0,\n",
              "                                                              min_impurity_split=None,\n",
              "                                                              min_samples_leaf=1,\n",
              "                                                              min_samples_split=2,\n",
              "                                                              min_weight_fraction_leaf=0.0,\n",
              "                                                              presort='deprecated',\n",
              "                                                              random_state=None,\n",
              "                                                              splitter='best'))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'desTree__max_depth': range(2, 100),\n",
              "                         'desTree__min_samples_leaf': range(2, 100)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eba8dfb9",
        "outputId": "211d9dd0-76c7-4aac-8232-4d7e43ba282a"
      },
      "source": [
        "search_des_tree.best_estimator_"
      ],
      "id": "eba8dfb9",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('desTree',\n",
              "                 DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
              "                                       max_depth=5, max_features=None,\n",
              "                                       max_leaf_nodes=None,\n",
              "                                       min_impurity_decrease=0.0,\n",
              "                                       min_impurity_split=None,\n",
              "                                       min_samples_leaf=52, min_samples_split=2,\n",
              "                                       min_weight_fraction_leaf=0.0,\n",
              "                                       presort='deprecated', random_state=None,\n",
              "                                       splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "070ba3ee",
        "outputId": "2005c9c6-f603-4f04-b675-16b423f09536"
      },
      "source": [
        "search_des_tree.best_score_"
      ],
      "id": "070ba3ee",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.005581306674089309"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de5f9537"
      },
      "source": [
        "# GridSearch Random forest"
      ],
      "id": "de5f9537"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cfab479",
        "outputId": "685e1ad2-bf11-4c35-fcf3-7072a912987e"
      },
      "source": [
        "model_rand_tree =  Pipeline([(\"scale\",StandardScaler()),(\"forest\",RandomForestRegressor(criterion=\"mae\"))]) \n",
        "param_grid_rand_tree =  {\"forest__n_estimators\": [10,50, 100, 300, 500, 1000],\n",
        "                         'forest__max_depth': np.linspace(5,500,10),\n",
        "                          \"forest__min_samples_leaf\" :[5] }\n",
        "search_rand_tree = GridSearchCV(model_rand_tree, param_grid=param_grid_rand_tree, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_rand_tree.fit(X,y)"
      ],
      "id": "1cfab479",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 11.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('forest',\n",
              "                                        RandomForestRegressor(bootstrap=True,\n",
              "                                                              ccp_alpha=0.0,\n",
              "                                                              criterion='mae',\n",
              "                                                              max_depth=None,\n",
              "                                                              max_features='auto',\n",
              "                                                              max_leaf_nodes=None,\n",
              "                                                              max_samples=None,\n",
              "                                                              min_impurity_decrease=0.0,\n",
              "                                                              min_impurity_split=None,\n",
              "                                                              min_samples_le...\n",
              "                                                              random_state=None,\n",
              "                                                              verbose=0,\n",
              "                                                              warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'forest__max_depth': array([  5.,  60., 115., 170., 225., 280., 335., 390., 445., 500.]),\n",
              "                         'forest__min_samples_leaf': [5],\n",
              "                         'forest__n_estimators': [10, 50, 100, 300, 500, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4681b8d6",
        "outputId": "54782ab9-8b42-4ac2-e2b6-9d506db32ebd"
      },
      "source": [
        "search_rand_tree.best_estimator_"
      ],
      "id": "4681b8d6",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('forest',\n",
              "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
              "                                       criterion='mae', max_depth=5.0,\n",
              "                                       max_features='auto', max_leaf_nodes=None,\n",
              "                                       max_samples=None,\n",
              "                                       min_impurity_decrease=0.0,\n",
              "                                       min_impurity_split=None,\n",
              "                                       min_samples_leaf=5, min_samples_split=2,\n",
              "                                       min_weight_fraction_leaf=0.0,\n",
              "                                       n_estimators=300, n_jobs=None,\n",
              "                                       oob_score=False, random_state=None,\n",
              "                                       verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5780f5b5",
        "outputId": "35b61369-20a7-4420-c2fb-b48d8c6e2894"
      },
      "source": [
        "search_rand_tree.best_score_"
      ],
      "id": "5780f5b5",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0054207494969551314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3e54d1c"
      },
      "source": [
        "# GridSearch Gradient Boost"
      ],
      "id": "c3e54d1c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d282a00",
        "outputId": "81c38361-839c-4181-d99b-7561b8c7e4b4"
      },
      "source": [
        "model_gboost = Pipeline([(\"scale\",StandardScaler()),(\"gboost\",GradientBoostingRegressor(criterion=\"mae\"))]) \n",
        "param_grid_gboost =  {'gboost__n_estimators': [10,50, 100, 300, 500, 1000],\n",
        "                      \"gboost__learning_rate\": [0.0001,0.001,0.003,0.01,0.03,0.1,0.3,1]}\n",
        "search_gboost = GridSearchCV(model_gboost, param_grid=param_grid_gboost, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_gboost.fit(X,y)"
      ],
      "id": "7d282a00",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 13.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('gboost',\n",
              "                                        GradientBoostingRegressor(alpha=0.9,\n",
              "                                                                  ccp_alpha=0.0,\n",
              "                                                                  criterion='mae',\n",
              "                                                                  init=None,\n",
              "                                                                  learning_rate=0.1,\n",
              "                                                                  loss='ls',\n",
              "                                                                  max_depth=3,\n",
              "                                                                  max_features=None,\n",
              "                                                                  max_leaf_nodes=None,\n",
              "                                                                  min_impurity_decrease=0.0,\n",
              "                                                                  min_impurity_split=None...\n",
              "                                                                  subsample=1.0,\n",
              "                                                                  tol=0.0001,\n",
              "                                                                  validation_fraction=0.1,\n",
              "                                                                  verbose=0,\n",
              "                                                                  warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'gboost__learning_rate': [0.0001, 0.001, 0.003, 0.01,\n",
              "                                                   0.03, 0.1, 0.3, 1],\n",
              "                         'gboost__n_estimators': [10, 50, 100, 300, 500, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee901b28",
        "outputId": "1dac5eed-027a-472d-f43b-765129d1eecf"
      },
      "source": [
        "search_gboost.best_estimator_"
      ],
      "id": "ee901b28",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('gboost',\n",
              "                 GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
              "                                           criterion='mae', init=None,\n",
              "                                           learning_rate=0.003, loss='ls',\n",
              "                                           max_depth=3, max_features=None,\n",
              "                                           max_leaf_nodes=None,\n",
              "                                           min_impurity_decrease=0.0,\n",
              "                                           min_impurity_split=None,\n",
              "                                           min_samples_leaf=1,\n",
              "                                           min_samples_split=2,\n",
              "                                           min_weight_fraction_leaf=0.0,\n",
              "                                           n_estimators=1000,\n",
              "                                           n_iter_no_change=None,\n",
              "                                           presort='deprecated',\n",
              "                                           random_state=None, subsample=1.0,\n",
              "                                           tol=0.0001, validation_fraction=0.1,\n",
              "                                           verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1766ccf",
        "outputId": "d7c0b094-7724-4d92-f81d-a18aaa73e93d"
      },
      "source": [
        "search_gboost.best_score_"
      ],
      "id": "b1766ccf",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.005436761118058518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a017cd12"
      },
      "source": [
        "# GridSearch Ada Boost"
      ],
      "id": "a017cd12"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f073172e",
        "outputId": "9a31e2b8-e5a4-4f51-b909-5203247510cd"
      },
      "source": [
        "model_aboost = Pipeline([(\"scale\",StandardScaler()),(\"aboost\",AdaBoostRegressor())])\n",
        "param_aboost =  {'aboost__n_estimators': [10,50, 100, 300, 500, 1000],\n",
        "                      \"aboost__learning_rate\": [0.0001,0.001,0.003,0.01,0.03,0.1,0.3,1],\n",
        "                      \"aboost__loss\":['linear', 'square', 'exponential']}\n",
        "search_aboost = GridSearchCV(model_aboost, param_grid=param_aboost, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_aboost.fit(X,y)"
      ],
      "id": "f073172e",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   20.1s\n",
            "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  5.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('aboost',\n",
              "                                        AdaBoostRegressor(base_estimator=None,\n",
              "                                                          learning_rate=1.0,\n",
              "                                                          loss='linear',\n",
              "                                                          n_estimators=50,\n",
              "                                                          random_state=None))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'aboost__learning_rate': [0.0001, 0.001, 0.003, 0.01,\n",
              "                                                   0.03, 0.1, 0.3, 1],\n",
              "                         'aboost__loss': ['linear', 'square', 'exponential'],\n",
              "                         'aboost__n_estimators': [10, 50, 100, 300, 500, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6159026a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8639a14f-df47-489f-973e-8eddc828dea5"
      },
      "source": [
        "search_aboost.best_estimator_"
      ],
      "id": "6159026a",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('aboost',\n",
              "                 AdaBoostRegressor(base_estimator=None, learning_rate=0.001,\n",
              "                                   loss='linear', n_estimators=100,\n",
              "                                   random_state=None))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50d8eac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065bed37-cf65-4ea6-947c-b6940b85b173"
      },
      "source": [
        "search_aboost.best_score_"
      ],
      "id": "50d8eac8",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.005406862519768918"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb529078"
      },
      "source": [
        "# Stacking "
      ],
      "id": "cb529078"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63bfd230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d017c6da-b594-4d1e-d77d-a8a50936f8b8"
      },
      "source": [
        "gboost = search_gboost.best_estimator_\n",
        "ridge = search_ridge.best_estimator_\n",
        "lasso = search_lasso.best_estimator_\n",
        "svm = search_svm.best_estimator_\n",
        "adaboost = search_aboost.best_estimator_\n",
        "forest = search_rand_tree.best_estimator_\n",
        "desTree = search_des_tree.best_estimator_\n",
        "sgd = search_sgd.best_estimator_\n",
        "knn = search_knn.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_stacking = VotingRegressor(\n",
        "    estimators = [(\"gboost\", gboost),(\"adaboost\", adaboost),(\"ridge\", ridge),(\"svm\", svm),\n",
        "                 (\"lasso\", lasso),(\"forest\", forest),(\"desTree\", desTree),(\"sgd\", sgd),(\"knn\", knn)],\n",
        "    weights = [1,1,1,1,1,1,1,1,1], # to equally weight the two models\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "score = cross_val_score(model_stacking, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "print(score.std())\n",
        "score.mean()"
      ],
      "id": "63bfd230",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00039474353092075546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.005409367344803464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiX8eWGenUXh"
      },
      "source": [
        "# Neural Network"
      ],
      "id": "XiX8eWGenUXh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bBGU-fFZni8C",
        "outputId": "f3743e82-b8fb-4c8f-b132-811a1c965265"
      },
      "source": [
        "data2 = pd.read_csv(\"predictions_vinci\")\n",
        "data2 = data2.drop(columns=feature_to_remove)\n",
        "data2.head()"
      ],
      "id": "bBGU-fFZni8C",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conf_std</th>\n",
              "      <th>perf_pred</th>\n",
              "      <th>perf_true</th>\n",
              "      <th>perf_low</th>\n",
              "      <th>perf_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.701848</td>\n",
              "      <td>-0.010684</td>\n",
              "      <td>-0.003090</td>\n",
              "      <td>-0.024262</td>\n",
              "      <td>0.002894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.711209</td>\n",
              "      <td>0.016711</td>\n",
              "      <td>0.005313</td>\n",
              "      <td>0.002909</td>\n",
              "      <td>0.030512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.727954</td>\n",
              "      <td>0.002645</td>\n",
              "      <td>-0.000881</td>\n",
              "      <td>-0.011407</td>\n",
              "      <td>0.016697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.727143</td>\n",
              "      <td>0.001604</td>\n",
              "      <td>0.005436</td>\n",
              "      <td>-0.012444</td>\n",
              "      <td>0.015653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.729361</td>\n",
              "      <td>-0.002763</td>\n",
              "      <td>-0.016659</td>\n",
              "      <td>-0.016779</td>\n",
              "      <td>0.011252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   conf_std  perf_pred  perf_true  perf_low  perf_high\n",
              "0  0.701848  -0.010684  -0.003090 -0.024262   0.002894\n",
              "1  0.711209   0.016711   0.005313  0.002909   0.030512\n",
              "2  0.727954   0.002645  -0.000881 -0.011407   0.016697\n",
              "3  0.727143   0.001604   0.005436 -0.012444   0.015653\n",
              "4  0.729361  -0.002763  -0.016659 -0.016779   0.011252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLVZTRhwoHvY"
      },
      "source": [
        "X2 = data2.copy().drop(columns=\"perf_true\")\n",
        "y2= data2[\"perf_true\"]"
      ],
      "id": "BLVZTRhwoHvY",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0hOtq77rqrdA",
        "outputId": "643f7b39-7281-4e48-c9c9-789f43383f43"
      },
      "source": [
        "X2[800:]"
      ],
      "id": "0hOtq77rqrdA",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conf_std</th>\n",
              "      <th>perf_pred</th>\n",
              "      <th>perf_low</th>\n",
              "      <th>perf_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>0.953856</td>\n",
              "      <td>0.000527</td>\n",
              "      <td>-0.010611</td>\n",
              "      <td>0.011665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>1.048799</td>\n",
              "      <td>0.007429</td>\n",
              "      <td>-0.004600</td>\n",
              "      <td>0.019457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>1.080792</td>\n",
              "      <td>0.004702</td>\n",
              "      <td>-0.007759</td>\n",
              "      <td>0.017164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>1.083552</td>\n",
              "      <td>0.010821</td>\n",
              "      <td>-0.001654</td>\n",
              "      <td>0.023296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>1.082054</td>\n",
              "      <td>0.003450</td>\n",
              "      <td>-0.008919</td>\n",
              "      <td>0.015818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>1.314958</td>\n",
              "      <td>-0.003736</td>\n",
              "      <td>-0.019600</td>\n",
              "      <td>0.012127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>1.191138</td>\n",
              "      <td>0.004214</td>\n",
              "      <td>-0.010282</td>\n",
              "      <td>0.018711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128</th>\n",
              "      <td>1.194974</td>\n",
              "      <td>0.003450</td>\n",
              "      <td>-0.010933</td>\n",
              "      <td>0.017832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1129</th>\n",
              "      <td>1.187985</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>-0.013949</td>\n",
              "      <td>0.014675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>1.191145</td>\n",
              "      <td>0.004383</td>\n",
              "      <td>-0.010032</td>\n",
              "      <td>0.018797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>331 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      conf_std  perf_pred  perf_low  perf_high\n",
              "800   0.953856   0.000527 -0.010611   0.011665\n",
              "801   1.048799   0.007429 -0.004600   0.019457\n",
              "802   1.080792   0.004702 -0.007759   0.017164\n",
              "803   1.083552   0.010821 -0.001654   0.023296\n",
              "804   1.082054   0.003450 -0.008919   0.015818\n",
              "...        ...        ...       ...        ...\n",
              "1126  1.314958  -0.003736 -0.019600   0.012127\n",
              "1127  1.191138   0.004214 -0.010282   0.018711\n",
              "1128  1.194974   0.003450 -0.010933   0.017832\n",
              "1129  1.187985   0.000363 -0.013949   0.014675\n",
              "1130  1.191145   0.004383 -0.010032   0.018797\n",
              "\n",
              "[331 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J51eiPqsngZH",
        "outputId": "f42ac416-ea88-491d-aeff-f31e20bc84f9"
      },
      "source": [
        "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "normalizer = Normalization() # Instantiate a \"normalizer\" layer\n",
        "normalizer.adapt(X2[:600]) # \"Fit\" it on the train set\n",
        "\n",
        "\n",
        "model_nn = Sequential()\n",
        "model_nn.add(normalizer)\n",
        "model_nn.add(layers.Dense(100, input_dim=7, activation='tanh'))  \n",
        "model_nn.add(layers.Dense(50, activation='tanh'))\n",
        "model_nn.add(layers.Dense(20, activation='tanh'))\n",
        "model_nn.add(layers.Dense(10, activation='tanh'))\n",
        "model_nn.add(layers.Dense(20, activation='tanh'))\n",
        "model_nn.add(layers.Dense(50, activation='tanh'))\n",
        "model_nn.add(layers.Dense(100, activation='tanh'))\n",
        "model_nn.add(layers.Dense(1, activation='linear')) \n",
        "\n",
        "# STEP 2: OPTIMIZATION METHODS\n",
        "model_nn.compile(loss='mae', optimizer='adam')\n",
        "\n",
        "# SETP 3: DATA AND FITTING METHODS\n",
        "model_nn.fit(X2[:800], y2[:800], batch_size=32, epochs=500, callbacks=[es],verbose=2)\n",
        "model_nn.evaluate(X2[800:],y2[800:])"
      ],
      "id": "J51eiPqsngZH",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "25/25 - 1s - loss: 0.0337\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 2/500\n",
            "25/25 - 0s - loss: 0.0073\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 3/500\n",
            "25/25 - 0s - loss: 0.0067\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 4/500\n",
            "25/25 - 0s - loss: 0.0066\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 5/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 6/500\n",
            "25/25 - 0s - loss: 0.0062\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 7/500\n",
            "25/25 - 0s - loss: 0.0063\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 8/500\n",
            "25/25 - 0s - loss: 0.0060\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 9/500\n",
            "25/25 - 0s - loss: 0.0066\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 10/500\n",
            "25/25 - 0s - loss: 0.0063\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 11/500\n",
            "25/25 - 0s - loss: 0.0063\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 12/500\n",
            "25/25 - 0s - loss: 0.0062\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 13/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 14/500\n",
            "25/25 - 0s - loss: 0.0060\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 15/500\n",
            "25/25 - 0s - loss: 0.0065\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 16/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 17/500\n",
            "25/25 - 0s - loss: 0.0060\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 18/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 19/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 20/500\n",
            "25/25 - 0s - loss: 0.0065\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 21/500\n",
            "25/25 - 0s - loss: 0.0079\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 22/500\n",
            "25/25 - 0s - loss: 0.0074\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 23/500\n",
            "25/25 - 0s - loss: 0.0073\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 24/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 25/500\n",
            "25/25 - 0s - loss: 0.0079\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 26/500\n",
            "25/25 - 0s - loss: 0.0084\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 27/500\n",
            "25/25 - 0s - loss: 0.0072\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 28/500\n",
            "25/25 - 0s - loss: 0.0065\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 29/500\n",
            "25/25 - 0s - loss: 0.0066\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 30/500\n",
            "25/25 - 0s - loss: 0.0065\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 31/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 32/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 33/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 34/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 35/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 36/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 37/500\n",
            "25/25 - 0s - loss: 0.0060\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 38/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 39/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 40/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 41/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 42/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 43/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 44/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 45/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 46/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 47/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 48/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 49/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 50/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 51/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 52/500\n",
            "25/25 - 0s - loss: 0.0066\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 53/500\n",
            "25/25 - 0s - loss: 0.0060\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 54/500\n",
            "25/25 - 0s - loss: 0.0068\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 55/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 56/500\n",
            "25/25 - 0s - loss: 0.0063\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 57/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 58/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 59/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 60/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 61/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 62/500\n",
            "25/25 - 0s - loss: 0.0067\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 63/500\n",
            "25/25 - 0s - loss: 0.0064\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 64/500\n",
            "25/25 - 0s - loss: 0.0065\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 65/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 66/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 67/500\n",
            "25/25 - 0s - loss: 0.0062\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 68/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 69/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 70/500\n",
            "25/25 - 0s - loss: 0.0060\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 71/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 72/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 73/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 74/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 75/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 76/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 77/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 78/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 79/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 80/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 81/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 82/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 83/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 84/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 85/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 86/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 87/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 88/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 89/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 90/500\n",
            "25/25 - 0s - loss: 0.0060\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 91/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 92/500\n",
            "25/25 - 0s - loss: 0.0064\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 93/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 94/500\n",
            "25/25 - 0s - loss: 0.0067\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 95/500\n",
            "25/25 - 0s - loss: 0.0060\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 96/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 97/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 98/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 99/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 100/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 101/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 102/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 103/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 104/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 105/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 106/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 107/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 108/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 109/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 110/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 111/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 112/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 113/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 114/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 115/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 116/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 117/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 118/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 119/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 120/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 121/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 122/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 123/500\n",
            "25/25 - 0s - loss: 0.0060\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 124/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 125/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 126/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 127/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 128/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 129/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 130/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 131/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 132/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 133/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 134/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 135/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 136/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 137/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 138/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 139/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 140/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 141/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 142/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 143/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 144/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 145/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 146/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 147/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 148/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 149/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 150/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 151/500\n",
            "25/25 - 0s - loss: 0.0058\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 152/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 153/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 154/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 155/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 156/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 157/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 158/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 159/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 160/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 161/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 162/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 163/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 164/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 165/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 166/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 167/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 168/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 169/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 170/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 171/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 172/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 173/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 174/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 175/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 176/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 177/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 178/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 179/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 180/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 181/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 182/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 183/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 184/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 185/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 186/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 187/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 188/500\n",
            "25/25 - 0s - loss: 0.0061\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 189/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 190/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 191/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 192/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 193/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 194/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 195/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 196/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 197/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 198/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 199/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 200/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 201/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 202/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 203/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 204/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 205/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 206/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 207/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 208/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 209/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 210/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 211/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 212/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 213/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 214/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 215/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 216/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 217/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 218/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 219/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 220/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 221/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 222/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 223/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 224/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 225/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 226/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 227/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 228/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 229/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 230/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 231/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 232/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 233/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 234/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 235/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 236/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 237/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 238/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 239/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 240/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 241/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 242/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 243/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 244/500\n",
            "25/25 - 0s - loss: 0.0059\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 245/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 246/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 247/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 248/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 249/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 250/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 251/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 252/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 253/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 254/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 255/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 256/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 257/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 258/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 259/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 260/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 261/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 262/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 263/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 264/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 265/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 266/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 267/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 268/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 269/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 270/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 271/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 272/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 273/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 274/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 275/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 276/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 277/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 278/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 279/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 280/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 281/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 282/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 283/500\n",
            "25/25 - 0s - loss: 0.0057\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 284/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 285/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 286/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 287/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 288/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 289/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 290/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 291/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 292/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 293/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 294/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 295/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 296/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 297/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 298/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 299/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 300/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 301/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 302/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 303/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 304/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 305/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 306/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 307/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 308/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 309/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 310/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 311/500\n",
            "25/25 - 0s - loss: 0.0051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 312/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 313/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 314/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 315/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 316/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 317/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 318/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 319/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 320/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 321/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 322/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 323/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 324/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 325/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 326/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 327/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 328/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 329/500\n",
            "25/25 - 0s - loss: 0.0056\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 330/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 331/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 332/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 333/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 334/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 335/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 336/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 337/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 338/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 339/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 340/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 341/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 342/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 343/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 344/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 345/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 346/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 347/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 348/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 349/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 350/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 351/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 352/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 353/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 354/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 355/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 356/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 357/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 358/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 359/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 360/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 361/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 362/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 363/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 364/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 365/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 366/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 367/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 368/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 369/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 370/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 371/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 372/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 373/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 374/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 375/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 376/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 377/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 378/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 379/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 380/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 381/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 382/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 383/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 384/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 385/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 386/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 387/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 388/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 389/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 390/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 391/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 392/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 393/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 394/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 395/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 396/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 397/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 398/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 399/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 400/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 401/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 402/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 403/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 404/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 405/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 406/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 407/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 408/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 409/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 410/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 411/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 412/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 413/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 414/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 415/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 416/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 417/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 418/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 419/500\n",
            "25/25 - 0s - loss: 0.0051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 420/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 421/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 422/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 423/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 424/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 425/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 426/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 427/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 428/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 429/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 430/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 431/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 432/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 433/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 434/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 435/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 436/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 437/500\n",
            "25/25 - 0s - loss: 0.0055\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 438/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 439/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 440/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 441/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 442/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 443/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 444/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 445/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 446/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 447/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 448/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 449/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 450/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 451/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 452/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 453/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 454/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 455/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 456/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 457/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 458/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 459/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 460/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 461/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 462/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 463/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 464/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 465/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 466/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 467/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 468/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 469/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 470/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 471/500\n",
            "25/25 - 0s - loss: 0.0051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 472/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 473/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 474/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 475/500\n",
            "25/25 - 0s - loss: 0.0051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 476/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 477/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 478/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 479/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 480/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 481/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 482/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 483/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 484/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 485/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 486/500\n",
            "25/25 - 0s - loss: 0.0054\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 487/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 488/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 489/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 490/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 491/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 492/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 493/500\n",
            "25/25 - 0s - loss: 0.0051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 494/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 495/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 496/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 497/500\n",
            "25/25 - 0s - loss: 0.0053\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 498/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 499/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "Epoch 500/500\n",
            "25/25 - 0s - loss: 0.0052\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.014233157970011234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaJHdNZIskVY",
        "outputId": "35c79095-32e2-4ec6-b97e-3d56b6235878"
      },
      "source": [
        "mae_arima2 = mean_absolute_error(data2.perf_true,data2.perf_pred)\n",
        "mae_arima2"
      ],
      "id": "vaJHdNZIskVY",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.007416762485498858"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHNjGZxEukM9"
      },
      "source": [
        "# GridSearch SVM 2"
      ],
      "id": "JHNjGZxEukM9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOk2lVegukM_",
        "outputId": "3e5ed17d-2873-4bfc-e100-60bdcf6fdb3b"
      },
      "source": [
        "SCORERS.keys()"
      ],
      "id": "VOk2lVegukM_",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1GqeS_kukNA",
        "outputId": "5996a0b5-aaa0-40ac-98b9-c74411007430"
      },
      "source": [
        "\n",
        "# Instanciate model\n",
        "model_svm2 = Pipeline([(\"scale\",StandardScaler()),(\"svm\",SVR())])\n",
        "\n",
        "# Hyperparameter search space\n",
        "search_space = {\n",
        "    'svm__kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
        "    'svm__C': stats.uniform(0.01, 1000),\n",
        "    'svm__gamma': stats.loguniform(0.001,10),\n",
        "    'svm__coef0': stats.uniform(-5,5),\n",
        "}\n",
        "\n",
        "# Instanciate Random Search\n",
        "search_svm2 = RandomizedSearchCV(\n",
        "    model_svm2, search_space,\n",
        "    n_jobs=-1, scoring='neg_mean_absolute_error', cv=5, n_iter=1, verbose=0)\n",
        "\n",
        "\n",
        "search_svm2.fit(X2,y2)"
      ],
      "id": "f1GqeS_kukNA",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=Pipeline(memory=None,\n",
              "                                      steps=[('scale',\n",
              "                                              StandardScaler(copy=True,\n",
              "                                                             with_mean=True,\n",
              "                                                             with_std=True)),\n",
              "                                             ('svm',\n",
              "                                              SVR(C=1.0, cache_size=200,\n",
              "                                                  coef0=0.0, degree=3,\n",
              "                                                  epsilon=0.1, gamma='scale',\n",
              "                                                  kernel='rbf', max_iter=-1,\n",
              "                                                  shrinking=True, tol=0.001,\n",
              "                                                  verbose=False))],\n",
              "                                      verbose=False),\n",
              "                   iid='deprecated', n_iter=1, n_jobs=-1,\n",
              "                   param_distri...t 0x7fdf16a39550>,\n",
              "                                        'svm__coef0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fdf0caca210>,\n",
              "                                        'svm__gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fdf0d2bbcd0>,\n",
              "                                        'svm__kernel': ['linear', 'poly', 'rbf',\n",
              "                                                        'sigmoid']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='neg_mean_absolute_error',\n",
              "                   verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE8DdYB7ukNE",
        "outputId": "3926efdd-e0fa-4751-b588-5bcbbbf7a6f4"
      },
      "source": [
        "search_svm2.best_estimator_"
      ],
      "id": "yE8DdYB7ukNE",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svm',\n",
              "                 SVR(C=396.3348781202654, cache_size=200,\n",
              "                     coef0=-0.291464764442412, degree=3, epsilon=0.1,\n",
              "                     gamma=0.015196274377184588, kernel='sigmoid', max_iter=-1,\n",
              "                     shrinking=True, tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu40ofMVukNE",
        "outputId": "99e53f9a-d412-4618-e707-46bc1f9b1153"
      },
      "source": [
        "search_svm2.best_score_"
      ],
      "id": "Yu40ofMVukNE",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-7.745159324355768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyGykFPrvPpu"
      },
      "source": [
        "# GridSearch KNN 2"
      ],
      "id": "xyGykFPrvPpu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDP_EbIyvPp5",
        "outputId": "2941f32f-5345-4875-8fb5-ef6a190b3425"
      },
      "source": [
        "model_knn2 = Pipeline([(\"scale\",StandardScaler()),(\"knn\",KNeighborsRegressor())])\n",
        "\n",
        "param_grid_knn =  {'knn__n_neighbors': range(2,50)}\n",
        "search_knn2 = GridSearchCV(model_knn2, param_grid=param_grid_knn, \n",
        "                          cv=5, n_jobs=-1, verbose=0, scoring='neg_mean_absolute_error')\n",
        "search_knn2.fit(X2,y2)"
      ],
      "id": "TDP_EbIyvPp5",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('knn',\n",
              "                                        KNeighborsRegressor(algorithm='auto',\n",
              "                                                            leaf_size=30,\n",
              "                                                            metric='minkowski',\n",
              "                                                            metric_params=None,\n",
              "                                                            n_jobs=None,\n",
              "                                                            n_neighbors=5, p=2,\n",
              "                                                            weights='uniform'))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'knn__n_neighbors': range(2, 50)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDaLp3FQvPp5",
        "outputId": "605f21f4-5128-48a3-ede1-5211ddd801d3"
      },
      "source": [
        "search_knn2.best_estimator_"
      ],
      "id": "JDaLp3FQvPp5",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('knn',\n",
              "                 KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
              "                                     metric='minkowski', metric_params=None,\n",
              "                                     n_jobs=None, n_neighbors=15, p=2,\n",
              "                                     weights='uniform'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc95oRSZvPp6",
        "outputId": "6a938aa4-0954-4b0b-d955-c4973c07e715"
      },
      "source": [
        "search_knn2.best_score_"
      ],
      "id": "Qc95oRSZvPp6",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.007927367926165635"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAclJd8mvu1T"
      },
      "source": [
        "# GridSearch Ridge 2\n",
        "\n"
      ],
      "id": "GAclJd8mvu1T"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c42cLq9ivu1e",
        "outputId": "aee26709-3897-4299-bd14-1e98eb071ccb"
      },
      "source": [
        "model_ridge2 = Pipeline([(\"scale\",StandardScaler()),(\"ridge\",Ridge())])\n",
        "param_grid_ridge =  {'ridge__alpha': np.linspace(0.0001,2,num=1000)}\n",
        "search_ridge2 = GridSearchCV(model_ridge2, param_grid=param_grid_ridge, \n",
        "                              cv=5, n_jobs=-1, verbose=0, scoring='neg_mean_absolute_error')\n",
        "search_ridge2.fit(X2,y2)"
      ],
      "id": "c42cLq9ivu1e",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('ridge',\n",
              "                                        Ridge(alpha=1.0, copy_X=True,\n",
              "                                              fit_intercept=True, max_iter=None,\n",
              "                                              normalize=False,\n",
              "                                              random_state=None, solver='auto',\n",
              "                                              tol=0.001))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'ridge__alpha': array([1.0000...\n",
              "       1.96196386e+00, 1.96396577e+00, 1.96596767e+00, 1.96796957e+00,\n",
              "       1.96997147e+00, 1.97197337e+00, 1.97397528e+00, 1.97597718e+00,\n",
              "       1.97797908e+00, 1.97998098e+00, 1.98198288e+00, 1.98398478e+00,\n",
              "       1.98598669e+00, 1.98798859e+00, 1.98999049e+00, 1.99199239e+00,\n",
              "       1.99399429e+00, 1.99599620e+00, 1.99799810e+00, 2.00000000e+00])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Yf6wVDvu1e",
        "outputId": "6eea3b09-3845-4450-be6c-bcc44701029d"
      },
      "source": [
        "search_ridge2.best_estimator_"
      ],
      "id": "u7Yf6wVDvu1e",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('ridge',\n",
              "                 Ridge(alpha=2.0, copy_X=True, fit_intercept=True,\n",
              "                       max_iter=None, normalize=False, random_state=None,\n",
              "                       solver='auto', tol=0.001))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdFahjB0vu1f",
        "outputId": "71f67760-252b-470d-c23a-e80a22168c87"
      },
      "source": [
        "search_ridge2.best_score_"
      ],
      "id": "gdFahjB0vu1f",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.007681612136228635"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVe7SBkc_Vxz"
      },
      "source": [
        "# GridSearch Lasso 2"
      ],
      "id": "VVe7SBkc_Vxz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UWpOVKd_Vx4",
        "outputId": "aafa8e07-6d40-4e29-b2a2-a892d4ce3b76"
      },
      "source": [
        "model_lasso2 = Pipeline([(\"scale\",StandardScaler()),(\"lasso\",Lasso())])\n",
        "param_grid_lasso =  {'lasso__alpha': np.linspace(0.0001,2,num=1000)}\n",
        "search_lasso2 = GridSearchCV(model_lasso2, param_grid=param_grid_lasso, \n",
        "                              cv=5, n_jobs=-1, verbose=0, scoring='neg_mean_absolute_error')\n",
        "search_lasso2.fit(X2,y2)"
      ],
      "id": "0UWpOVKd_Vx4",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('lasso',\n",
              "                                        Lasso(alpha=1.0, copy_X=True,\n",
              "                                              fit_intercept=True, max_iter=1000,\n",
              "                                              normalize=False, positive=False,\n",
              "                                              precompute=False,\n",
              "                                              random_state=None,\n",
              "                                              selection='cyclic', tol=0.0001,\n",
              "                                              warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='depreca...\n",
              "       1.96196386e+00, 1.96396577e+00, 1.96596767e+00, 1.96796957e+00,\n",
              "       1.96997147e+00, 1.97197337e+00, 1.97397528e+00, 1.97597718e+00,\n",
              "       1.97797908e+00, 1.97998098e+00, 1.98198288e+00, 1.98398478e+00,\n",
              "       1.98598669e+00, 1.98798859e+00, 1.98999049e+00, 1.99199239e+00,\n",
              "       1.99399429e+00, 1.99599620e+00, 1.99799810e+00, 2.00000000e+00])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuX9TRPl_Vx9",
        "outputId": "5948a0bb-3e50-4c79-d54c-6f940617fec9"
      },
      "source": [
        "search_lasso2.best_estimator_"
      ],
      "id": "PuX9TRPl_Vx9",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('lasso',\n",
              "                 Lasso(alpha=0.0001, copy_X=True, fit_intercept=True,\n",
              "                       max_iter=1000, normalize=False, positive=False,\n",
              "                       precompute=False, random_state=None, selection='cyclic',\n",
              "                       tol=0.0001, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhL77-Cf_Vx_",
        "outputId": "a292ff83-afff-44cb-88ca-9bb7c7d8e42e"
      },
      "source": [
        "search_lasso2.best_score_"
      ],
      "id": "NhL77-Cf_Vx_",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.007581140276205475"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRGfg0gu_oZR"
      },
      "source": [
        "# GridSearch  SGD"
      ],
      "id": "HRGfg0gu_oZR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2RiSggZ_oZc",
        "outputId": "d3ad3330-3536-40ea-d4ca-37216648438b"
      },
      "source": [
        "model_sgd2 = Pipeline([(\"scale\",StandardScaler()),(\"sgd\",SGDRegressor())]) \n",
        "param_grid_sgd =  {'sgd__alpha': np.linspace(0.0001,2,num=100),\n",
        "                  'sgd__penalty': [\"l2\", \"l1\", \"elasticnet\"],\n",
        "                  \"sgd__l1_ratio\" :np.linspace(0,1,num=10) }\n",
        "search_sgd2 = GridSearchCV(model_sgd2, param_grid=param_grid_sgd, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_sgd2.fit(X2,y2)"
      ],
      "id": "Q2RiSggZ_oZc",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3000 candidates, totalling 15000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done 4540 tasks      | elapsed:   22.6s\n",
            "[Parallel(n_jobs=-1)]: Done 11036 tasks      | elapsed:   54.3s\n",
            "[Parallel(n_jobs=-1)]: Done 15000 out of 15000 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('sgd',\n",
              "                                        SGDRegressor(alpha=0.0001,\n",
              "                                                     average=False,\n",
              "                                                     early_stopping=False,\n",
              "                                                     epsilon=0.1, eta0=0.01,\n",
              "                                                     fit_intercept=True,\n",
              "                                                     l1_ratio=0.15,\n",
              "                                                     learning_rate='invscaling',\n",
              "                                                     loss='squared_loss',\n",
              "                                                     max_iter=1000,\n",
              "                                                     n_iter_no_change=5,\n",
              "                                                     penalty='l...\n",
              "       1.85859293e+00, 1.87879394e+00, 1.89899495e+00, 1.91919596e+00,\n",
              "       1.93939697e+00, 1.95959798e+00, 1.97979899e+00, 2.00000000e+00]),\n",
              "                         'sgd__l1_ratio': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
              "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n",
              "                         'sgd__penalty': ['l2', 'l1', 'elasticnet']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RGor1-f_oZd",
        "outputId": "e90a654a-1b35-4219-d5ba-09a83530260d"
      },
      "source": [
        "search_sgd2.best_estimator_"
      ],
      "id": "4RGor1-f_oZd",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('sgd',\n",
              "                 SGDRegressor(alpha=0.040502020202020206, average=False,\n",
              "                              early_stopping=False, epsilon=0.1, eta0=0.01,\n",
              "                              fit_intercept=True, l1_ratio=0.4444444444444444,\n",
              "                              learning_rate='invscaling', loss='squared_loss',\n",
              "                              max_iter=1000, n_iter_no_change=5, penalty='l2',\n",
              "                              power_t=0.25, random_state=None, shuffle=True,\n",
              "                              tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                              warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXtjbLer_oZd",
        "outputId": "5e9c672d-8953-461e-85dc-e9b6db3bf7ff"
      },
      "source": [
        "search_sgd2.best_score_"
      ],
      "id": "gXtjbLer_oZd",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.007360201756036721"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykvrdvc4_6yg"
      },
      "source": [
        "# GridSearch Descision Tree"
      ],
      "id": "Ykvrdvc4_6yg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4xnhfMH_6yq",
        "outputId": "752bf5fb-23a1-42d7-c62e-02039c879233"
      },
      "source": [
        "model_des_tree2 = Pipeline([(\"scale\",StandardScaler()),(\"desTree\",DecisionTreeRegressor())]) \n",
        "param_grid_des_tree =  {'desTree__max_depth': range(2,100),\n",
        "                  \"desTree__min_samples_leaf\" :range(2,100) }\n",
        "search_des_tree2 = GridSearchCV(model_des_tree2, param_grid=param_grid_des_tree, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_des_tree2.fit(X2,y2)"
      ],
      "id": "e4xnhfMH_6yq",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9604 candidates, totalling 48020 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done 2332 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=-1)]: Done 5580 tasks      | elapsed:   29.2s\n",
            "[Parallel(n_jobs=-1)]: Done 10108 tasks      | elapsed:   53.7s\n",
            "[Parallel(n_jobs=-1)]: Done 15948 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 23068 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done 31500 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done 41212 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=-1)]: Done 48020 out of 48020 | elapsed:  4.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('desTree',\n",
              "                                        DecisionTreeRegressor(ccp_alpha=0.0,\n",
              "                                                              criterion='mse',\n",
              "                                                              max_depth=None,\n",
              "                                                              max_features=None,\n",
              "                                                              max_leaf_nodes=None,\n",
              "                                                              min_impurity_decrease=0.0,\n",
              "                                                              min_impurity_split=None,\n",
              "                                                              min_samples_leaf=1,\n",
              "                                                              min_samples_split=2,\n",
              "                                                              min_weight_fraction_leaf=0.0,\n",
              "                                                              presort='deprecated',\n",
              "                                                              random_state=None,\n",
              "                                                              splitter='best'))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'desTree__max_depth': range(2, 100),\n",
              "                         'desTree__min_samples_leaf': range(2, 100)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqvRXBCJ_6yr",
        "outputId": "35c12500-bdaa-4398-9a76-272d89ce1727"
      },
      "source": [
        "search_des_tree2.best_estimator_"
      ],
      "id": "bqvRXBCJ_6yr",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('desTree',\n",
              "                 DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
              "                                       max_depth=5, max_features=None,\n",
              "                                       max_leaf_nodes=None,\n",
              "                                       min_impurity_decrease=0.0,\n",
              "                                       min_impurity_split=None,\n",
              "                                       min_samples_leaf=44, min_samples_split=2,\n",
              "                                       min_weight_fraction_leaf=0.0,\n",
              "                                       presort='deprecated', random_state=None,\n",
              "                                       splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IqqUc8__6yr",
        "outputId": "92918128-d029-4872-ce92-a173c6e84cbc"
      },
      "source": [
        "search_des_tree2.best_score_"
      ],
      "id": "0IqqUc8__6yr",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.008132664502081796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnbXIJvWAJiw"
      },
      "source": [
        "# GridSearch Random forest"
      ],
      "id": "dnbXIJvWAJiw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoWsLSzkAJix",
        "outputId": "8be81068-5154-4bb1-e71b-c9095d2280fd"
      },
      "source": [
        "model_rand_tree2 =  Pipeline([(\"scale\",StandardScaler()),(\"forest\",RandomForestRegressor(criterion=\"mae\"))]) \n",
        "param_grid_rand_tree =  {\"forest__n_estimators\": [10,50, 100, 300, 500, 1000],\n",
        "                         'forest__max_depth': np.linspace(5,500,10),\n",
        "                          \"forest__min_samples_leaf\" :[5] }\n",
        "search_rand_tree2 = GridSearchCV(model_rand_tree2, param_grid=param_grid_rand_tree, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_rand_tree2.fit(X2,y2)"
      ],
      "id": "MoWsLSzkAJix",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  9.3min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 19.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('forest',\n",
              "                                        RandomForestRegressor(bootstrap=True,\n",
              "                                                              ccp_alpha=0.0,\n",
              "                                                              criterion='mae',\n",
              "                                                              max_depth=None,\n",
              "                                                              max_features='auto',\n",
              "                                                              max_leaf_nodes=None,\n",
              "                                                              max_samples=None,\n",
              "                                                              min_impurity_decrease=0.0,\n",
              "                                                              min_impurity_split=None,\n",
              "                                                              min_samples_le...\n",
              "                                                              random_state=None,\n",
              "                                                              verbose=0,\n",
              "                                                              warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'forest__max_depth': array([  5.,  60., 115., 170., 225., 280., 335., 390., 445., 500.]),\n",
              "                         'forest__min_samples_leaf': [5],\n",
              "                         'forest__n_estimators': [10, 50, 100, 300, 500, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYOYrL1KAJix",
        "outputId": "e2c1aea1-f6cc-4c90-993f-f598212daf9b"
      },
      "source": [
        "search_rand_tree2.best_estimator_"
      ],
      "id": "GYOYrL1KAJix",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('forest',\n",
              "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
              "                                       criterion='mae', max_depth=5.0,\n",
              "                                       max_features='auto', max_leaf_nodes=None,\n",
              "                                       max_samples=None,\n",
              "                                       min_impurity_decrease=0.0,\n",
              "                                       min_impurity_split=None,\n",
              "                                       min_samples_leaf=5, min_samples_split=2,\n",
              "                                       min_weight_fraction_leaf=0.0,\n",
              "                                       n_estimators=50, n_jobs=None,\n",
              "                                       oob_score=False, random_state=None,\n",
              "                                       verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgHzPV15AJiy",
        "outputId": "b52148a1-47f1-4ec9-c99f-e1e74da55095"
      },
      "source": [
        "search_rand_tree2.best_score_"
      ],
      "id": "AgHzPV15AJiy",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.007765839762594437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsazNyRvAbDn"
      },
      "source": [
        "# GridSearch Gradient Boost"
      ],
      "id": "IsazNyRvAbDn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0d9R1KvAbDs",
        "outputId": "7db0af04-4c0c-4a95-ca23-3736ea7dc5f1"
      },
      "source": [
        "model_gboost2 = Pipeline([(\"scale\",StandardScaler()),(\"gboost\",GradientBoostingRegressor(criterion=\"mae\"))]) \n",
        "param_grid_gboost =  {'gboost__n_estimators': [10,50, 100, 300, 500, 1000],\n",
        "                      \"gboost__learning_rate\": [0.0001,0.001,0.003,0.01,0.03,0.1,0.3,1]}\n",
        "search_gboost2 = GridSearchCV(model_gboost2, param_grid=param_grid_gboost, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_gboost2.fit(X2,y2)"
      ],
      "id": "M0d9R1KvAbDs",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 24.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('gboost',\n",
              "                                        GradientBoostingRegressor(alpha=0.9,\n",
              "                                                                  ccp_alpha=0.0,\n",
              "                                                                  criterion='mae',\n",
              "                                                                  init=None,\n",
              "                                                                  learning_rate=0.1,\n",
              "                                                                  loss='ls',\n",
              "                                                                  max_depth=3,\n",
              "                                                                  max_features=None,\n",
              "                                                                  max_leaf_nodes=None,\n",
              "                                                                  min_impurity_decrease=0.0,\n",
              "                                                                  min_impurity_split=None...\n",
              "                                                                  subsample=1.0,\n",
              "                                                                  tol=0.0001,\n",
              "                                                                  validation_fraction=0.1,\n",
              "                                                                  verbose=0,\n",
              "                                                                  warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'gboost__learning_rate': [0.0001, 0.001, 0.003, 0.01,\n",
              "                                                   0.03, 0.1, 0.3, 1],\n",
              "                         'gboost__n_estimators': [10, 50, 100, 300, 500, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWkkzuWWAbDt",
        "outputId": "15b1b16a-adcc-43cf-c0dc-456437508d53"
      },
      "source": [
        "search_gboost2.best_estimator_"
      ],
      "id": "ZWkkzuWWAbDt",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('gboost',\n",
              "                 GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
              "                                           criterion='mae', init=None,\n",
              "                                           learning_rate=0.01, loss='ls',\n",
              "                                           max_depth=3, max_features=None,\n",
              "                                           max_leaf_nodes=None,\n",
              "                                           min_impurity_decrease=0.0,\n",
              "                                           min_impurity_split=None,\n",
              "                                           min_samples_leaf=1,\n",
              "                                           min_samples_split=2,\n",
              "                                           min_weight_fraction_leaf=0.0,\n",
              "                                           n_estimators=300,\n",
              "                                           n_iter_no_change=None,\n",
              "                                           presort='deprecated',\n",
              "                                           random_state=None, subsample=1.0,\n",
              "                                           tol=0.0001, validation_fraction=0.1,\n",
              "                                           verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymn7lSIBAbDt",
        "outputId": "9a3ac861-adad-4ea9-884f-4844157d541a"
      },
      "source": [
        "search_gboost2.best_score_"
      ],
      "id": "ymn7lSIBAbDt",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.007801477185637107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJQJ-U37Aqbc"
      },
      "source": [
        "# GridSearch Ada Boost"
      ],
      "id": "FJQJ-U37Aqbc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n1UpZIVAqbd",
        "outputId": "8ee6de89-c912-44d3-a126-238c096df6fd"
      },
      "source": [
        "model_aboost2 = Pipeline([(\"scale\",StandardScaler()),(\"aboost\",AdaBoostRegressor())])\n",
        "param_aboost =  {'aboost__n_estimators': [10,50, 100, 300, 500, 1000],\n",
        "                      \"aboost__learning_rate\": [0.0001,0.001,0.003,0.01,0.03,0.1,0.3,1],\n",
        "                      \"aboost__loss\":['linear', 'square', 'exponential']}\n",
        "search_aboost2 = GridSearchCV(model_aboost2, param_grid=param_aboost, \n",
        "                              cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
        "search_aboost2.fit(X2,y2)"
      ],
      "id": "-n1UpZIVAqbd",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   24.7s\n",
            "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  6.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scale',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('aboost',\n",
              "                                        AdaBoostRegressor(base_estimator=None,\n",
              "                                                          learning_rate=1.0,\n",
              "                                                          loss='linear',\n",
              "                                                          n_estimators=50,\n",
              "                                                          random_state=None))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'aboost__learning_rate': [0.0001, 0.001, 0.003, 0.01,\n",
              "                                                   0.03, 0.1, 0.3, 1],\n",
              "                         'aboost__loss': ['linear', 'square', 'exponential'],\n",
              "                         'aboost__n_estimators': [10, 50, 100, 300, 500, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17ict-7lAqbd",
        "outputId": "0eb346ac-b174-4e22-ad56-dfd808df1bd3"
      },
      "source": [
        "search_aboost2.best_estimator_"
      ],
      "id": "17ict-7lAqbd",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('aboost',\n",
              "                 AdaBoostRegressor(base_estimator=None, learning_rate=0.0001,\n",
              "                                   loss='square', n_estimators=10,\n",
              "                                   random_state=None))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YQhU90-Aqbd",
        "outputId": "58ea616b-d173-4276-808e-b76dc5b951c8"
      },
      "source": [
        "search_aboost2.best_score_"
      ],
      "id": "6YQhU90-Aqbd",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.008100839297311781"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSu9ic07A-_l"
      },
      "source": [
        "# Stacking "
      ],
      "id": "DSu9ic07A-_l"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXW_u7q4A-_l",
        "outputId": "02c678da-b7f8-43fa-d03e-a765b901c558"
      },
      "source": [
        "gboost2 = search_gboost2.best_estimator_\n",
        "ridge2 = search_ridge2.best_estimator_\n",
        "lasso2 = search_lasso2.best_estimator_\n",
        "svm2 = search_svm2.best_estimator_\n",
        "adaboost2= search_aboost2.best_estimator_\n",
        "forest2 = search_rand_tree2.best_estimator_\n",
        "desTree2 = search_des_tree2.best_estimator_\n",
        "sgd2 = search_sgd2.best_estimator_\n",
        "knn2 = search_knn2.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_stacking2 = VotingRegressor(\n",
        "    estimators = [(\"gboost\", gboost2),(\"adaboost\", adaboost2),(\"ridge\", ridge2),(\"svm\", svm2),\n",
        "                 (\"lasso\", lasso2),(\"forest\", forest2),(\"desTree\", desTree2),(\"sgd\", sgd2),(\"knn\", knn2)],\n",
        "    weights = [1,1,1,1,1,1,1,1,1], # to equally weight the two models\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "score = cross_val_score(model_stacking2, X2, y2, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "print(score.std())\n",
        "score.mean()"
      ],
      "id": "IXW_u7q4A-_l",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8179322931285649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.8624261402315867"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}